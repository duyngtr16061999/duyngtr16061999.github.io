---
---
@article{nguyen2023improving,
  abbr={EMNLP},
  title={Improving multimodal sentiment analysis: Supervised angular margin-based contrastive learning for enhanced fusion representation},
  author={Nguyen, Cong-Duy and Nguyen, Thong and Vu, Anh and Luu, Tuan},
  journal={Proceedings of EMNLP (Findings)},
  year={2023},
  selected={true},
  abstract={},
  arxiv={2312.02227}
}

@article{nguyen2024expand,
  abbr={ACMMM},
  title={Expand BERT Representation with Visual Information via Grounded Language Learning with Multimodal Partial Alignment},
  author={Nguyen, Cong-Duy and Vu-Le, The-Anh and Nguyen, Thong and Quan, Tho and Luu, Tuan},
  journal={Proceedings of ACM MM},
  year={2023},
  selected={true},
  abstract={},
  arxiv={2312.01592}
}

@article{nguyen2023read,
  abbr={AAAI},
  title={READ-PVLA: Recurrent Adapter with Partial Video-Language Alignment for Parameter-Efficient Transfer Learning in Low-Resource Video-Language Modeling},
  author={Nguyen, Thong and Wu, Xiaobao and Dong, Xinshuai and Le, Khoi and Hu, Zhiyuan and Nguyen, Cong-Duy and Ng, See-Kiong, and Luu, Tuan},
  journal={Proceedings of AAAI},
  year={2024},
  selected={false},
  abstract={Fully fine-tuning pretrained large-scale transformer models has become a popular paradigm for video-language modeling tasks, such as temporal language grounding and video-language summarization. With a growing number of tasks and limited training data, such full fine-tuning approach leads to costly model storage and unstable training. To overcome these shortcomings, we introduce lightweight adapters to the pre-trained model and only update them at fine-tuning time. However, existing adapters fail to capture intrinsic temporal relations among video frames or textual words. Moreover, they neglect the preservation of critical task-related information that flows from the raw video-language input into the adapter's low-dimensional space. To address these issues, we first propose a novel REcurrent ADapter (READ) that employs recurrent computation to enable temporal modeling capability. Second, we propose Partial Video-Language Alignment (PVLA) objective via the use of partial optimal transport to maintain task-related information flowing into our READ modules. We validate our READ-PVLA framework through extensive experiments where READ-PVLA significantly outperforms all existing fine-tuning strategies on multiple low-resource temporal language grounding and video-language summarization benchmarks.},
  arxiv={2312.06950}
}

@article{nguyen2023demaformer,
  abbr={EMNLP},
  title={DemaFormer: Damped Exponential Moving Average Transformer with Energy-Based Modeling for Temporal Language Grounding},
  author={Nguyen, Thong and Wu, Xiaobao and Dong, Xinshuai and Nguyen, Cong-Duy and Ng, See-Kiong and Luu, Tuan},
  journal={Proceedings of EMNLP (Findings)},
  year={2023},
  selected={false},
  abstract={Temporal Language Grounding seeks to localize video moments that semantically correspond to a natural language query. Recent advances employ the attention mechanism to learn the relations between video moments and the text query. However, naive attention might not be able to appropriately capture such relations, resulting in ineffective distributions where target video moments are difficult to separate from the remaining ones. To resolve the issue, we propose an energy-based model framework to explicitly learn moment-query distributions. Moreover, we propose DemaFormer, a novel Transformer-based architecture that utilizes exponential moving average with a learnable damping factor to effectively encode moment-query inputs. Comprehensive experiments on four public temporal language grounding datasets showcase the superiority of our methods over the state-of-the-art baselines.},
  arxiv={2312.02549}
}

@article{nguyen2023gradient,
  abbr={ACL},
  title={Gradient-Boosted Decision Tree for Listwise Context Model in Multimodal Review Helpfulness Prediction},
  author={Nguyen, Thong and Wu, Xiaobao and Dong, Xinshuai and Luu, Tuan and Nguyen, Cong-Duy and Hai, Zhen and Bing, Lidong},
  journal={Proceedings of ACL (Findings)},
  year={2023},
  selected={false},
  abstract={Multimodal Review Helpfulness Prediction (MRHP) aims to rank product reviews based on predicted helpfulness scores and has been widely applied in e-commerce via presenting customers with useful reviews. Previous studies commonly employ fully-connected neural networks (FCNNs) as the final score predictor and pairwise loss as the training objective. However, FCNNs have been shown to perform inefficient splitting for review features, making the model difficult to clearly differentiate helpful from unhelpful reviews. Furthermore, pairwise objective, which works on review pairs, may not completely capture the MRHP goal to produce the ranking for the entire review list, and possibly induces low generalization during testing. To address these issues, we propose a listwise attention network that clearly captures the MRHP ranking context and a listwise optimization objective that enhances model generalization. We further propose gradient-boosted decision tree as the score predictor to efficaciously partition product reviews' representations. Extensive experiments demonstrate that our method achieves state-of-the-art results and polished generalization performance on two large-scale MRHP benchmark datasets.},
  arxiv={2305.12678},
  code={https://github.com/nguyentthong/gbdt_listwise_mrhp}
}

@article{nguyen2022adaptive,
  abbr={EMNLP},
  title={Adaptive Contrastive Learning on Multimodal Transformer for Review Helpfulness Predictions},
  author={Nguyen, Thong and Wu, Xiaobao and Luu, Tuan and Nguyen, Cong-Duy and Hai, Zhen and Bing, Lidong},
  journal={Proceedings of EMNLP},
  year={2022},
  selected={false},
  abstract={Modern Review Helpfulness Prediction systems are dependent upon multiple modalities, typically texts and images. Unfortunately, those contemporary approaches pay scarce attention to polish representations of cross-modal relations and tend to suffer from inferior optimization. This might cause harm to model's predictions in numerous cases. To overcome the aforementioned issues, we propose Multimodal Contrastive Learning for Multimodal Review Helpfulness Prediction (MRHP) problem, concentrating on mutual information between input modalities to explicitly elaborate cross-modal relations. In addition, we introduce Adaptive Weighting scheme for our contrastive learning approach in order to increase flexibility in optimization. Lastly, we propose Multimodal Interaction module to address the unalignment nature of multimodal data, thereby assisting the model in producing more reasonable multimodal representations. Experimental results show that our method outperforms prior baselines and achieves state-of-the-art results on two publicly available benchmark datasets for MRHP problem.},
  arxiv={2211.03524},
  code={https://github.com/nguyentthong/adaptive_contrastive_mrhp}
}

@article{wu2024affinity,
  abbr={AAAI},
  title={On the Affinity, Rationality, and Diversity of Hierarchical Topic Modeling},
  author={Xiaobao Wu and Fengjun Pan and Thong Nguyen and Yichao Feng and Chaoqun Liu and Cong-Duy Nguyen and Anh Tuan Luu},
  journal={Proceedings of AAAI},
  year={2024},
  selected={false},
  abstract={},
  arxiv={2401.14113}
}


@article{nguyen22e_interspeech,
  abbr={InterSpeech},
  title={Adaptive Contrastive Learning on Multimodal Transformer for Review Helpfulness Predictions},
  author={Tuan-Duy H. Nguyen and Duy Phung and Cong-Duy Nguyen and Hieu Minh Tran and Manh Luong and Tin Duy Vo and Hung Hai Bui and Dinh Phung and Dat Quoc Nguyen},
  journal={Proceedings of InterSpeech Show & Tell Demonstrations},
  year={2022},
  selected={false},
  abstract={},
  code={https://github.com/VinAIResearch/VinAI_Translate}
  }

@article{NGUYEN2024122217,
  abbr={ESWA},
  title={Supervised learning models for social bot detection: Literature review and benchmark},
  author={Hoang-Dung Nguyen and Duc Q. Nguyen and Cong-Duy Nguyen and Phong T. To and Danh H. Nguyen and Huy Nguyen-Gia and Long H. Tran and Anh Q. Tran and An Dang-Hieu and Anh Nguyen-Duc and Tho Quan},
  journal={Expert Systems with Applications},
  year={2024},
  selected={false},
  abstract={}
}